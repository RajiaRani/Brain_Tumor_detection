{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a665d024",
   "metadata": {},
   "source": [
    "**<center><font size=5>Build your brain tumor AI model</font></center>**\n",
    "***\n",
    "\n",
    "\n",
    "**Table of Contents**\n",
    "- <a href='#intro'>1. Project Overview and Objectives</a>\n",
    "    - <a href='#dataset'>1.1. Data Set Description</a>\n",
    "    - <a href='#tumor'>1.2. What is Brain Tumor?</a>\n",
    "- <a href='#env'>2. Setting up the Environment</a>\n",
    "- <a href='#import'>3. Data Import and Preprocessing</a>\n",
    "- <a href='#cnn'>4. Building the AI model</a>\n",
    "- <a href='#cnn'>5. Model evaluation</a>\n",
    "- <a href='#concl'>6. Testing the model</a>\n",
    "- <a href='#concl'>7. Conclusion</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a7fa5",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Welcome to the Vizuara AI Labs project notebook. This guide is designed to help you build your own machine learning model for medical imaging diagnosis, starting with brain tumor detection. The structure of this notebook is organized into modular building blocks, allowing you to easily adapt and apply this workflow to other projects, such as heart disease classification, by modifying specific sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a770d0",
   "metadata": {},
   "source": [
    "# <a id='intro'>1. Project Overview and Objectives</a>\n",
    "\n",
    "The main purpose of this project was to build a CNN model that would classify if subject has a tumor or not base on MRI scan.\n",
    "\n",
    "## <a id='dataset'>1.1. Data Set Description</a>\n",
    "\n",
    "The image data that was used for this problem is [Brain MRI Images for Brain Tumor Detection](https://www.kaggle.com/navoneel/brain-mri-images-for-brain-tumor-detection). It conists of MRI scans of two classes:\n",
    "\n",
    "* `NO` - no tumor, encoded as `0`\n",
    "* `YES` - tumor, encoded as `1`\n",
    "\n",
    "Unfortunately, the data set description doesn't hold any information where this MRI scans come from and so on.\n",
    "\n",
    "## <a id='tumor'>1.2. What is Brain Tumor?</a>\n",
    "\n",
    "> A brain tumor occurs when abnormal cells form within the brain. There are two main types of tumors: cancerous (malignant) tumors and benign tumors. Cancerous tumors can be divided into primary tumors, which start within the brain, and secondary tumors, which have spread from elsewhere, known as brain metastasis tumors. All types of brain tumors may produce symptoms that vary depending on the part of the brain involved. These symptoms may include headaches, seizures, problems with vision, vomiting and mental changes. The headache is classically worse in the morning and goes away with vomiting. Other symptoms may include difficulty walking, speaking or with sensations. As the disease progresses, unconsciousness may occur.\n",
    ">\n",
    "> ![](https://upload.wikimedia.org/wikipedia/commons/5/5f/Hirnmetastase_MRT-T1_KM.jpg)\n",
    ">\n",
    "> *Brain metastasis in the right cerebral hemisphere from lung cancer, shown on magnetic resonance imaging.*\n",
    "\n",
    "Source: [Wikipedia](https://en.wikipedia.org/wiki/Brain_tumor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf132ac0",
   "metadata": {},
   "source": [
    "# <a id='intro'>2. Setting up the Environment: Import Statements</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4341e5",
   "metadata": {},
   "source": [
    "\n",
    "## import os\n",
    "**What:**  \n",
    "Python module to interact with files and folders.\n",
    "\n",
    "**Why:**  \n",
    "Used to load images, read directories, and create file paths.\n",
    "\n",
    "**Advantages:**  \n",
    "- Built-in  \n",
    "- Works on all operating systems  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Wrong usage can delete files  \n",
    "- Not directly ML related  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76950bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # os = Python’s Operating System module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65935d40",
   "metadata": {},
   "source": [
    "\n",
    "## import keras\n",
    "**What:**  \n",
    "High-level deep learning library. Used to build, train, and evaluate neural networks easily.\n",
    "\n",
    "**Advantages:**  \n",
    "- Very simple  \n",
    "- Beginner-friendly  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Less flexible than PyTorch  \n",
    "- Version mismatch possible  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6086da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abroadhub/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363f67a",
   "metadata": {},
   "source": [
    "\n",
    "## from keras.models import Sequential\n",
    "**What:**  \n",
    "A linear stack of layers. Used when building simple CNN models layer-by-layer.\n",
    "\n",
    "**Advantages:**  \n",
    "- Very easy to write  \n",
    "- Good for basic CNNs  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Cannot handle complex architectures  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10583306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9145b1",
   "metadata": {},
   "source": [
    "## Conv2D\n",
    "**What:**  \n",
    "Convolution layer to extract features from images. Used in all CNNs for feature detection.\n",
    "\n",
    "**Advantages:**  \n",
    "- Learns edges, textures, shapes  \n",
    "- Key part of image models  \n",
    "\n",
    "**Disadvantages:**  \n",
    "- Heavy computation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f9b99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be026589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e761e",
   "metadata": {},
   "source": [
    "# <a id='intro'>3(a) Data Import</a>\n",
    "\n",
    "When working on different projects, you will need to load a different dataset. The best way to load a dataset is as follows:\n",
    "\n",
    "(a) Upload the dataset to Google Drive\n",
    "\n",
    "(b) The image path will be `/content/drive/My Drive/name_of_your_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1663ec0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec5fdf3",
   "metadata": {},
   "source": [
    "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a129d",
   "metadata": {},
   "source": [
    "# <a id='intro'>3(b) Data Processing</a>\n",
    "\n",
    "1. First, we create a data list for storing image data in numpy array form\n",
    "2. Secondly, we create a paths list for storing paths of all images\n",
    "3. Thirdly, we create result list for storing one hot encoded form of target class whether normal or tumor\n",
    "\n",
    "The label 0 is transformed into [1, 0] (one-hot encoding).\n",
    "\n",
    "The label 1 is transformed into [0, 1] (one-hot encoding)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24785fd2",
   "metadata": {},
   "source": [
    "# How CNN Inputs Are Generated (Image → Tensor Pipeline)\n",
    "\n",
    "We want to convert images into a numeric format that a CNN can understand.\n",
    "\n",
    "## Step 0: Folder Structure\n",
    "\n",
    "We assume images are stored like this:\n",
    "\n",
    "dataset/  \n",
    "├── cat/  \n",
    "│   ├── cat1.jpg  \n",
    "│   ├── cat2.jpg  \n",
    "├── dog/  \n",
    "│   ├── dog1.jpg  \n",
    "│   ├── dog2.jpg  \n",
    "└── horse/  \n",
    "    ├── horse1.jpg  \n",
    "\n",
    "Each folder name is the **class label**.\n",
    "\n",
    "## Step 1: Load Image\n",
    "\n",
    "We read an image from disk using PIL:\n",
    "\n",
    "- Open file: `\"dataset/cat/cat1.jpg\"`\n",
    "- Still in image format (not numbers yet)\n",
    "\n",
    "## Step 2: Resize Image\n",
    "\n",
    "CNN needs **fixed size images**, e.g.:\n",
    "\n",
    "- 128 × 128\n",
    "- or 224 × 224\n",
    "\n",
    "So we resize every image to the same size to keep input shape consistent.\n",
    "\n",
    "## Step 3: Convert to NumPy Array\n",
    "\n",
    "Image → NumPy Array:\n",
    "\n",
    "- Shape becomes: `(height, width, channels)`\n",
    "- Example: `(128, 128, 3)` for RGB\n",
    "\n",
    "Now image is just a bunch of numbers.\n",
    "\n",
    "## Step 4: Normalize (Scale Pixel Values)\n",
    "\n",
    "Raw pixels are in range **0–255**.\n",
    "\n",
    "We divide by 255.0 to bring values into **0–1** range:\n",
    "\n",
    "- Helps faster and more stable training.\n",
    "\n",
    "## Step 5: Stack All Images into One Big Array\n",
    "\n",
    "If we have `N` images, each of shape `(H, W, C)`, then:\n",
    "\n",
    "- Final input shape: `(N, H, W, C)`\n",
    "\n",
    "This is what we pass to the CNN.\n",
    "\n",
    "## Simple Diagram: Image → Tensor\n",
    "\n",
    "Raw Images (JPG/PNG)  \n",
    "↓ (load with PIL)  \n",
    "Resized Images (128×128)  \n",
    "↓ (convert with NumPy)  \n",
    "Arrays of Shape (128, 128, 3)  \n",
    "↓ (divide by 255)  \n",
    "Normalized Tensors  \n",
    "↓ (stack all)  \n",
    "Final Input: Shape (N, 128, 128, 3) → fed into CNN\n",
    "\n",
    "## Labels (y)\n",
    "\n",
    "- Each image belongs to a class: `cat`, `dog`, `horse`, etc.\n",
    "- We convert text labels into numbers and then (optionally) into one-hot vectors.\n",
    "- Example one-hot for 3 classes:\n",
    "\n",
    "cat   → [1, 0, 0]  \n",
    "dog   → [0, 1, 0]  \n",
    "horse → [0, 0, 1]\n",
    "\n",
    "These become the **target outputs** for training the CNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3a6e18",
   "metadata": {},
   "source": [
    "# Explanation: Processing Brain Tumor Images (YES category)\n",
    "\n",
    "This code loads all “YES” (tumor present) images, resizes them, converts them into arrays, and assigns label = 0.\n",
    "\n",
    "\n",
    "\n",
    "## Step 1: Initialize empty lists\n",
    "\n",
    "data = []      → stores the processed images as NumPy arrays  \n",
    "paths = []     → stores file paths of images  \n",
    "result = []    → stores encoded labels for each image  \n",
    "\n",
    "\n",
    "\n",
    "## Step 2: Loop through all files inside the \"yes\" folder\n",
    "\n",
    "for r, d, f in os.walk('/content/drive/My Drive/brain_tumor_dataset/yes'):\n",
    "\n",
    "- `os.walk()` goes through all subfolders and files inside the directory.\n",
    "- r = root folder path  \n",
    "- d = subdirectories  \n",
    "- f = file names  \n",
    "\n",
    "We only want `.jpg` images.\n",
    "\n",
    "\n",
    "\n",
    "## Step 3: Build full file paths\n",
    "\n",
    "paths.append(os.path.join(r, file))\n",
    "\n",
    "- Joins folder path + file name  \n",
    "- Example:  \n",
    "  \"/content/.../yes\" + \"Y1.jpg\" → \"/content/.../yes/Y1.jpg\"  \n",
    "\n",
    "We store all image paths in `paths` list.\n",
    "\n",
    "\n",
    "\n",
    "## Step 4: Process each image one by one\n",
    "\n",
    "for path in paths:\n",
    "\n",
    "\n",
    "\n",
    "## Step 5: Open the image\n",
    "\n",
    "img = Image.open(path)\n",
    "\n",
    "- Loads the image from disk into memory.\n",
    "\n",
    "\n",
    "\n",
    "## Step 6: Resize the image\n",
    "\n",
    "img = img.resize((128,128))\n",
    "\n",
    "- All images must be the **same size** (128×128).  \n",
    "- CNNs cannot accept images of different sizes.\n",
    "\n",
    "\n",
    "\n",
    "## Step 7: Convert the image to NumPy array\n",
    "\n",
    "img = np.array(img)\n",
    "\n",
    "- Changes the image into a tensor of shape (128, 128, 3).  \n",
    "- CNNs only understand numbers, not images.\n",
    "\n",
    "\n",
    "\n",
    "## Step 8: Filter only RGB images\n",
    "\n",
    "if(img.shape == (128,128,3)):\n",
    "\n",
    "Why?\n",
    "\n",
    "- Some images may be grayscale (128×128×1).  \n",
    "- CNN expects 3 channels (RGB).  \n",
    "- This line ensures only valid RGB images are added.\n",
    "\n",
    "\n",
    "\n",
    "## Step 9: Store the processed image\n",
    "\n",
    "data.append(np.array(img))\n",
    "\n",
    "- Adds the image array to `data` list.  \n",
    "- `data` becomes your X (input images).\n",
    "\n",
    "\n",
    "\n",
    "## Step 10: Add the label for \"YES\" tumor class\n",
    "\n",
    "result.append(encoder.transform([[0]]).toarray())\n",
    "\n",
    "Important:\n",
    "\n",
    "- `0` is the label for YES (tumor present).  \n",
    "- `encoder.transform([[0]])` converts label 0 into **one-hot format**.  \n",
    "- Example if 2 classes:  \n",
    "  0 → [1, 0]  \n",
    "  1 → [0, 1]\n",
    "- `.toarray()` converts sparse matrix to normal NumPy array.\n",
    "\n",
    "So for every tumor image, we add:\n",
    "\n",
    "Label → `[1, 0]`\n",
    "\n",
    "This becomes your y (output labels).\n",
    "\n",
    "\n",
    "## Final understanding\n",
    "\n",
    "### data → list of processed images  \n",
    "Shape example: (128,128,3)\n",
    "\n",
    "### result → list of labels for each image  \n",
    "Example: [ [1,0], [1,0], [1,0], ... ]\n",
    "\n",
    "You now have:\n",
    "\n",
    "- **X = data**\n",
    "- **y = result**\n",
    "\n",
    "Ready for training the CNN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Initialize empty lists\n",
    "data = []   # stores the processed images as NumPy arrays \n",
    "paths = []  # stores file paths of images \n",
    "result = [] #  stores encoded labels for each image\n",
    " \n",
    "  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
